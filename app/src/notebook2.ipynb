{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importando las librerias \"\"\"\n",
    "from bs4 import BeautifulSoup #(bs4)Es una Biblioteca que nos da el html\n",
    "from selenium import webdriver # contorlador del navegador\n",
    "from selenium.common.exceptions import WebDriverException #Manejar excepciones del navegador\n",
    "import os \n",
    "from os import environ #Importa el diccionario completo con todas las variables de entorno como PATH, HOME, USERNAME, etc.\n",
    "from os import pathsep #se utiliza para separar las diferentes rutas en la variable de entorno\n",
    "from datetime import date #poder obtener la fecja de extracion\n",
    "import re\n",
    "import pandas as pd #poder manipular los datos en excel\n",
    "import openpyxl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Declaracion de la ubicacion y ejecucion del controlador \"\"\"\n",
    "chrome_driver_path = 'C:/Users/LEANM/OneDrive/Escritorio/Extractor ebay/chromedriver' #Declarando ruta del driver\n",
    "os.environ[\"PATH\"] += os.pathsep + chrome_driver_path # parchando la ruta (dejandola fija)\n",
    "#crear el objeto del controlador que nos abrira googleDrive\n",
    "url = webdriver.Chrome() #Abrir googleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Declaramos el dataframe vacio\"\"\"\n",
    "data_frame_title =[]\n",
    "data_frame_product_status =[]\n",
    "data_frame_price =[]\n",
    "data_frame_seller_score =[]\n",
    "data_frame_price_before =[]\n",
    "data_frame_link =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Informacion del sitio a extraer \"\"\"\n",
    "main_site = 'https://www.ebay.com/' #Pagina a la que se extareran los datos\n",
    "url.get(main_site+\"/sch/i.html?_from=R40&_trksid=p2380057.m570.l1313&_nkw=ryzen&_sacat=0\") #Personalisando lo que busca driver\n",
    "#Guardar todo el contenido en una variable\n",
    "page = BeautifulSoup(url.page_source,'html.parser') # page nos almacena todo el html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Recorrer la sopa (Buscar la informacion en concreto) \"\"\"\n",
    "for content in page.find_all('li',class_='s-item'): #Recorro page en contenido para que contenido tenga toda la informacion de page(el parser)\n",
    "\n",
    "    #Titulo\n",
    "    title = content.find('div',class_='s-item__title') #Definiendo variable\n",
    "    if title: #si esto es verdad\n",
    "        title = title.text.replace('Anuncio nuevo', '').strip()\n",
    "        data_frame_title.append(title) #imprimir mensaje\n",
    "    else: data_frame_title.append('No se encontro titulo') # Imprimir no se encontro\n",
    "\n",
    "    #Estado del producto\n",
    "    product_status = content.find('span',class_='SECONDARY_INFO') #Definiendo variable\n",
    "    if product_status:#si esto es verdad\n",
    "        data_frame_product_status.append(product_status.text)#imprimir mensaje\n",
    "    else: data_frame_product_status.append('No se encontro estado') # Imprimir no se encontro\n",
    "\n",
    "    #Precio\n",
    "    price = content.find('span',class_='s-item__price')#Definiendo variable\n",
    "    if price:#si esto es verdad\n",
    "        price = re.sub(r'\\s+', '', price.text.replace('COP $', ''))\n",
    "        price = price.split('.')[0]\n",
    "        print(price)\n",
    "        data_frame_price.append(price)#imprimir mensaje\n",
    "    else: data_frame_price.append('No se encontro precio') # Imprimir no se encontro\n",
    "\n",
    "    #Puntuacion vendedor\n",
    "    seller_score = content.find('span',class_='s-item__etrs-text')#Definiendo variable\n",
    "    if seller_score: #si esto es verdad\n",
    "        data_frame_seller_score.append(seller_score.text)#imprimir mensaje\n",
    "    else: data_frame_seller_score.append('No se encontro Puntuacion_vendedor') # Imprimir no se encontro\n",
    "    \n",
    "    #Precio de antes\n",
    "    price_before = content.find('span',class_='STRIKETHROUGH')#Definiendo variable\n",
    "    if price_before: #si esto es verdad\n",
    "        data_frame_price_before.append(price_before.text)#imprimir mensaje\n",
    "    else: data_frame_price_before.append('No se encontro precio de antes') # Imprimir no se encontro\n",
    "    \n",
    "    #link\n",
    "    link = content.find('a',class_='s-item__link')#Definiendo variable\n",
    "    if link: #si esto es verdad\n",
    "        data_frame_link.append(link['href'])#imprimir mensaje\n",
    "    else: data_frame_link.append('No se encontro enlace') # Imprimir no se encontro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Declaramos el dataframe y le pasamos un diccionario como argumento \"\"\"\n",
    "together_data_frame_list = pd.DataFrame({\n",
    "    'TITULO':data_frame_title,\n",
    "    'ESTADO DEL PRODUCTO':data_frame_product_status,\n",
    "    'PRECIO':data_frame_price,\n",
    "    'PUNTAJE DEL VENDEDOR':data_frame_seller_score,\n",
    "    'PRECIO ANTES':data_frame_price_before,\n",
    "    'LINK':data_frame_link\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se exportó todo con éxito.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Creando el csv (Exportar a excel)\"\"\"\n",
    "# Exportar el DataFrame a un archivo de Excel\n",
    "together_data_frame_list.to_excel(r'C:\\Users\\LEANM\\OneDrive\\Escritorio\\tutorial scraping ebay\\app\\data\\dataset.xlsx', index=False, header=True, sheet_name='Datos')\n",
    "\n",
    "if os.path.exists(r'C:\\Users\\LEANM\\OneDrive\\Escritorio\\tutorial scraping ebay\\app\\data\\dataset.xlsx'):\n",
    "    print('Se exportó todo con éxito.')\n",
    "else:\n",
    "    print('Hubo un error al exportar los datos.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
